---
title: Practical Applications for a Distributed Modeling Framework for Protected Data
author:
  - name: John Muschelli III
    email: jmusche1@jhu.edu
    affiliation: Johns Hopkins Bloomberg School of Public Health
    footnote: Corresponding Author
address:
  - code: Johns Hopkins Bloomberg School of Public Health
    address: Department of Biostatistics, 615 N Wolfe St, Baltimore MD, 21205
abstract: |
  We present 2 practical approaches to fitting generalized linear models in a distributed framework.  The use case for this framework is where multiple sites (e.g. hospitals) have data with protected or private information that cannot be shared, but aggregated data can be, and each site can send aggregated data across the internet.  
  We present the first strategy: using synced folder services, such as Dropbox or Box Sync, to share the aggregated data.  The second strategy involves creating an application programming interface (API), where sites submit the data to this service.  This work relies on the R statistical software; we provide an R package of examples and code to create an API on DigitalOcean.
journal: "An awesome journal"
date: "`r Sys.Date()`"
bibliography: refs.bib
#linenumbers: true
#numbersections: true
csl: elsevier-harvard.csl
output: rticles::elsevier_article
---

```{r setup, include = FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
library(dplyr)
```


# Introduction
We introduce a distrbuted framework to analyze data from multiple sources with the data being properly siloed. The motivation for this problem is simple: we would like to fit a generalized linear model on data from multiple sites (e.g. hospitals), where the indvidual patient-level data or otherwise private data never leaves the server (siloed), which is usually behind a firewall.  The idea is that a model is specified, and sent to each site where a summary statistic is computed and returned to the modeling service/site.  The model is then updated and, if necessary, the process is completed until the model is fit until convergence.  The goal is to fit the exact model as if the full data was accessible.  

The alternatives to this process is meta-analysis or one-step solutions.  There are drawbacks to a meta-analysis approach in that the model and statistics must be specified and commonly the data is gathered once from each site.  Also, if sites present estimates from models with different predictors, it is unclear how meta-analysis adequately handles this variability.  The process below ensures that the same model, with the same predictors, is fit at each site.  Any updated analysis requires additional correspondence between the modeler and the site data analyst, which slows down the process of analysis and creates more hurdles.  


Though this type of framework has been discussed many times, we implemented a practical solution in an R package that allows researchers to practically implement this system with real data.  The solution can be done a number of ways; we implemented 1) code to deploy an API (application programming interface) on a remote server and 2) scripts to calculate the model if using a synced folder, backed by services such as Dropbox or Box Sync.  

If this process is automated through a system such as the application programming interface or a synced folder described below, this alleviates the need for staff to run the computations individually (which can cause errors).  Moreover, when a hospital no longer wants to participate in the modeling process, they can simply shut off their server.  


Chen et al. describes these processes as one-shot or multi-shot analyses.  


# Motivating Example

In the most simple modeling example, let us estimate a linear regression of an outcome $Y$ on a set of covariates $X$.  Let there be $K$ hospitals, and $Y$ and $X$ are on the data on all hospitals $1, \dots, K$. 

$$
E[Y | X] = X\beta
$$

Let us also say that we are interested in $p$ covariates, and $n_{k}$ is the total number of records at hospital $k$ and $n = \sum_{1}^{k} n_{k}$, is the number of rows of $Y$ and $X$, thus $Y$ is an $n\text{x}1$ vector and $X$ is a $n\text{x}p$ matrix.  To estimate $\beta$, we would use:
$$
(X'X)^{-1} X'Y
$$
where $X'X$ is a $p\text{x}p$ matrix and $X'Y$ is a $p\times{1}$ vector. 

Since we don't have access to $X$, but rather a series of $X_{k}$, $k = 1, \dots, K$, we can use methods such as parallelized gradient descent approaches [@zinkevich2010parallelized; @mcdonald2009efficient] or approximate maximum-likelihood approaches [@duncan1980approximate].  Regardless, for almost any approach, the gradient or some reduced-dimensional summary is required to be aggregated together to get the estimate of $\beta$ at the full population level.  Now, if we combine these models with models that require iterative fitting, such as Generalized Linear Models (GLMs), there needs to be a lot of communication and recomputation of summaries to get a final estimate.  These approaches work well in distributed computing systems (such as computing clusters or GPUs), but have a much higher likelihood for errors if human interaction is required at each iteration.  This human interaction is a common practice for most clinical data, which we wish to show a simple solution to create the distributed computing much simpler.




# Methods
`plumber` is an R package that creates APIs (Application programming interfaces) for and from R [@plumber].  Though there are many frameworks to create APIs, such as Node.js and Flask, we will focus on `plumber` for a number of reasons.  Overall, the API needs a computational backbone for this process to work.  As `plumber` is based in R, we know that the server will have this already installed.  Another reason is that the statisticians and data analysts that will be running the models will likely be using a statistical language, usually either R or Python.  Though we will focus on R, the ideas here can be extended to other languages and systems.  We are not experts in distributed computing, but would like to show how this process is possible, overlooking obvious hurdles such as authentication, load balancing, network issues, debugging, and overall security on the server side. 

The framework is as follows: a developer makes an R package with a `plumber` API specification inside of it of the inputs and outputs necessary for a specific model.  For example, fitting a linear model where the analyst specifies predictors and an outcome.  The API has endpoints that take in this model, run a specified computation on the server (behind the hospital firewall), and returns a result that has only aggregate data (such as a $p\text{x}p$ matrix).  The API logs the output for potential future debugging and audits of the process.  The analysis system receives the output for each hospital, creates and updated estimate of the model and runs the next iteration from each hospital again until convergence. Thus, this system. 

```{r, out.width = "100%", fig.cap="Proposed Framework.  The modeler/analyst specifies a model, sends the model specification to an endpoint on each hospital API, a computation is run and returned to the analyst and aggregated (usually a gradient).  The model estimates are updated and the process repeats until the model converges.  "}
knitr::include_graphics("sketch.jpg")
```


# Issues
Though the system may seem simple to describe, many obstacles exist.  Mainly opening any system that interacts with patient data or a database (even if it were a spreadsheet) is a potential security risk which most clinical centers will not allow.  Though this caution is warranted, it may be more secure than the alternative of sending estimates in other communication systems such as email.  Though emailing has the upside of a human ensuring only aggregate data is transferred, it drastically increases the potential for wrong computation.  For example, the `plumber` API can have checks on the data for missingness, quality, the sample size is equal to that of the previous iteration/model, and other issues, which may be done at varying levels at each institution.

If the institution allows the API to be supported, then a server is required, and usually an administrator to oversee it.  This administrator is usually trained in information systems or information technology, which is likely not part of the clinical team.  Thus, providing support or interaction from the clinical team to the technical personnel can be more costly than simply emailing estiamtes.  Lastly, many institutions and research groups would like a "handle" on what models are being fit with their data, and thus limits on the API need to be created, which may cause other issues or limitations on teh proposed framework.  

These downsides are vastly outweighed when the API gets repeated use.  Thsu, fitting one model one time does not generally warrant the work needed to set up this framework.  





References {#references .unnumbered}
==========
